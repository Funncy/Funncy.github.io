---
layout: post
title: "[Bigdata] -  빅데이터 기초 03 : 빅데이터 채택과 계획 고려사항 "
subtitle:   "Bigdata - 빅데이터 기초"
categories: ml
tags: ml bigdata
comments: true
---

### 빅데이터 채택과 계획 고려사항

빅데이터 계획은 본질적으로 전략적이며 비즈니스 중심적으로 설계되어야 한다. 빅데이터 채택은 `변환`보다는 `혁신`에 가깝다. 비즈니스 `변환`은 일반적으로 효율과 성과를 증가시키기 위한 위험성이 낮은 시도이다. 그러나 `혁신`은 비즈니스의 생산, 서비스, 조직의 구조를 근본적으로 바꾸기 때문에, 반드시 `사고의 변화`가 있어야한다.

+ [조직의 전제조건](#조직의-전제조건)
+ [데이터 조달](#데이터-조달)
+ [사생활 침해](#사생활-침해)
+ [보안](#보안)
+ [출처](#출처)
+ [제한된 실시간 자원](#제한된-실시간-자원)
+ [성능을 저해하는 요인들](#성능을-저해하는-요인들)
+ [별도의 거버넌스 요구사항](#별도의-거버넌스-요구사항)
+ [별도의 방법론](#별도의-방법론)
+ [빅데이터 분석 수명주기](#빅데이터-분석-수명주기)

---

### 조직의 전제조건

데이터 분석을 통해 가치 창출을 하기 위해서는 기업은 데이터 관리와 빅데이터 거버넌스 프레임워크를 가지고 있어야 한다. 온전한 절차와 과정을 충분히 감당할 능력이 있는 담당자들이 필요하다. 추가로, 데이터의 품질도 평가되어야 한다.
기업의 요구사항과 추세를 같이할 수 있게끔, 빅데이터 환경의 확장 혹은 확대가 계획되어 있는 로드맵이 정의되어야 한다.

---

### 데이터 조달

빅데이터 솔루션은 오픈소스 플랫폼 및 저가의 상용 하드웨어를 활용할 수 있기 때문에 습득 자체는 경제적일 수도 있다. 그러나 외부 데이터를 획득하는 데 상당한 예산이 필요하다. 

`외부 데이터` 소스는 `정부 데이터` 소스와 `상업용 데이터` 시장을 포함한다. 지리 정보와 같은 정부 제공 데이터는 무료일 수도 있다. 그러나 대부분의 상업용 데이터는 구입해야 하고, 지속적으로 구하기 위해서는 구독료도 지속적으로 지불해야한다. 

> 대한민국은 법적 제재로 인해 외부 데이터 구입이 가장 어려운 나라 가운데 하나이다.

---

### 사생활 침해

`사생활 침해` 문제를 갖고 있지 않은 데이터 세트들을 조합하여 같이 분석하다 보면, 사적인 정보를 폭로하게 될 수도 있다. 이러한 사생활 침해 문제를 다루려면, `데이터 태깅`과 `익명화`를 위한 특별한 기술뿐만 아니라, 축적된 데이터의 특성과 이와 관련된 `데이터 개인 정보 보호 규정`에 대한 이해가 필요하다.

---

### 보안

빅데이터 보안은 `인증` 및 `권한 부여`를 통해, 데이터 네트워크와 저장 공간의 안정성을 확보하는 것을 포함한다. `사용자 등급`에 따라 `데이터 접근 권한`을 다르게 하기도 한다. 

> 전통적인 관계형 데이터베이스 관리 시스템과 달리, NoSQL 데이터베이스는 일반적으로 강력한 내장 보안 매커니즘을 제공하지 않는다. 대신에, 데이터가 일반 텍스트로 변환되는 단순한 HTTP기반 API에 의존하기 때문에, 네트워크 기반 공격에 취약해진다.

---

### 출처

출처는 `데이터의 소스`와 `데이터가 처리된 방법`에 관한 정보들을 일컫는다. 이 정보는 데이터의 진위 여부와 품질을 판단하는 데 도움이 되며, 감사 용도로도 사용될 수 있다. 중요한 것은 `빅데이터의 상태`가 변할 때 마다 `메타데이터`로 기록되어 있는 출처 정보를 잘 기록해야 한다는 것이다. 출처 정보는 데이터의 근원이 기록된 정보로 초기화될 수 있다. 출처 정보는 `분석 결과의 가치`를 뒷받침하는 데 필수적이다.

---

### 제한된 실시간 자원

대다수 오픈소스 빅데이터 솔루션 및 제품들은 `일괄처리(batch)` 지향적이다. 그러나 이제 스트리밍 데이터 분석을 지원하는 `실시간 처리`가 가능한 오픈소스 제품이 출시되고 있다.

---

### 성능을 저해하는 요인들

대용량의 데이터를 처리하는 데 있어서 관건은 `빅데이터 솔루션의 성능`이다. 예를들어, `복잡한 검색 알고리즘`과 결합된 `대형 데이터 세트`의 경우 긴 쿼리 시간을 야기하게 된다. 또한, `네트워크 대역폭` 또한 성능을 결정짓는 중요한 요소이다.

---

### 별도의 거버넌스 요구사항

데이터와 솔루션 환경 자체를 조절하고 표준화하여 발전시키기 위해서 `거버넌스 프레임워크`가 필요하다. 빅데이터 거버넌스 프레임워크는 다음과 같은 사항들을 포함한다.

+ `데이터 태킹` 및 이에 사용되는 `메타데이터의 표준화`
+ 사용 가능한 `외부 데이터의 규제` 정책
+ `데이터 프라이버시` 및 `익명화` 관리 정책
+ 데이터 소스 및 `분석 결과 보관` 정책
+ `데이터 정제 및 여과` 지침 설립에 관한 정책

---

### 별도의 방법론

빅데이터 솔루션에 `데이터의 출입을 제어`하는 방법론이 필요하다. 처리된 데이터를 `반복적으로 정제`할 수 있도록 `피드백 루프`를 설정하는 방법을 고려해야 한다. 각 주기에서 나온 피드백들은 데이터 준비 혹은 데이터 분석 단계의 변화를 줘서 `시스템을 세분화`하는 기회를 제공한다.


![이미지](https://Funncy.github.io/assets/img/bigdata/03/2020-05-12-method.png "method")

---

### 빅데이터 분석 수명주기

데이터의 `획득`, `처리`, `분석` 및 `용도 변경`과 관련된 작업을 구성하는 `단계별 방법론`이 필요하다. 분석 수명주기와 더불어 데이터 분석 팀의 교육과 장비, 그리고 팀의 구성원들에 대해서도 고려해야 한다.

![이미지](https://Funncy.github.io/assets/img/bigdata/03/2020-05-12-lifecycle.png "method")

#### 빅데이터 사례 평가

각 빅데이터 분석 수명주기의 시작은 분석의 `정당성`과 `동기`, `목표`가 잘 정의된 `비즈니스 사례 평가`에서 시작한다. 실제 분석을 하기 전에 비즈니스 사례를 작성, 평가하고 이를 승인하는 작업이 필요하다. 비즈니스 사례에서 문서화된 요구사항에 따라, 비즈니스가 갖고 있는 문제가 진짜 빅데이터 문제인지 결정할 수 있다. 

> 빅데이터 문제는 빅데이터의 특징인 `크기`, `속도`, `다양성`과 직접적으로 연관되어 있는 비즈니스 문제를 일컫는다.

#### 데이터 식별

분석에 필요한 데이터와 소스를 식별한다. `다양한 데이터 출처`를 식별하게 되면 숨겨진 `패턴`과 `연관성을` 찾아낼 확률이 높아진다. 가능한 한 많은 종류의 데이터 출처를 식별하는 것이 인사이트를 제공하는 데 도움이 된다.

#### 데이터 획득과 여과

이전 단계에서 식별된 데이터 출처에서 데이터를 획득한다. 획득한 데이터는 분석 목표에 부합하는지, 오염되지 않았는지 확인하여 제거하는 여과 단계를 거친다.
어떤 분석에 대해서 여과된 데이터는 다른 종류의 분석을 할 때는 가치 있는 데이터일 수 있다. 그러므로 여과 가정을 거치기 전에 원본 데이터의 복사본을 저장해 놓는 것이 좋다. 

> 데이터 출처로부터 자동적으로 메타데이터를 데이터에 추가시켜 분류, 쿼리의 성능 향상을 이끌어낼 수 있다. 메타데이터의 예시로는, `데이터 크기`, `구조`, `소스 정보`, 생성 혹은 수집 `날짜`와 `시간`, `언어`별 정보 등이 있다.

#### 데이터 추출

입력 데이터의 일부는 분석에 적합하지 않은 형식을 갖고 있을 수 있다. 외부에서 얻은 데이터의 경우, 이러한 문제를 갖고 있을 가능성이 높다. 상이한 데이터를 추출하고, 빅데이터 솔루션에 맞는 데이터 형식으로 변환하여 분석에 사용할 수 있도록 하는 과정이다. 

#### 데이터 검증 및 정제

잘못된 데이터는 분석 결과를 왜곡, 위조할 수 있따. 데이터 검증 및 정제 단계는 복잡한 검증 규칙을 만들거나, 알고 있는 잘못된 데이터를 제거하는 과정이다. 종종 서로 다른 데이터 세트에서 `중복된 데이터`가 입력된다. 이러한 `중복성`을 이용하여 데이터를 `검증`하고, `누락된 데이터`를 채울 수 있따.

#### 데이터 통합 및 표현

데이터는 여러 개의 세트에 분산되어 존재할 수 있으므로, 그 데이터 세트들은 날짜나 ID 같은 공통된 필드를 통해 함께 연결되어야 한다. (`결합연산` join operation)

이 단계는 다음과 같은 차이점들 때문에 매우 어려운 작업을 수행해야 한다.

+ `데이터 구조` : 형식은 같더라도 모델은 매우 다를 수 있다.
+ `의미` : `suername`과 `last name`과 같이, 라벨이 다르더라도 같은 의미를 내포하는 경우가 존재한다. 

이 작업은 사람의 개입이 없이 자동으로 실행되는 복잡한 로직이 필요하다.
데이터의 재사용을 높이기 위해서, 이 단계에서는 향후의 데이터 분석 요구사항들이 고려되어야 한다. 같은 데이터가 여러 형태로 저장될 수 있음을 이해하는 것이 중요하다.

#### 데이터 분석

보통 한 가자 이상의 방법으로 실제 분석 작업을 수행한다. 본질적으로 `반복`적일 수 있는데, 특히 탐색적 데이터 분석의 경우, 적절한 `패턴` 혹은 `상관관계`를 밝혀낼 때 까지 분석을 반복한다.

+ `확증적 데이터 분석` : 관측된 현상의 원인을 제안하는 `연역적` 접근법이다. 가설이라고 부르는 현상의 원인 혹은 `가정이 먼저 제시`된다. 데이터를 분석하여 가설을 입증 혹은 반증하고, `최종적인 답을 제시`한다. 

> 일반적으로 `데이터 샘플링 기법`이 활용된다. 미리 원인을 가정하기 때문에 가설과 다른 발견을 하거나 이상치가 탐지되는 경우 보통 무시한다.

+ 탐색적 데이터 분석 : 데이터마이닝과 연관된 `귀납적` 방법이다. 현상의 원인에 대한 이해를 도출하기 위해 데이터를 탐색적으로 분석한다. 명확한 답은 제공하지 못하더라도, 패턴이나 이상치탐지를 용이하게 할 수 있는 `일반적인 방향`을 제시한다.

#### 데이터 시각화

데이터 시각화 기법을 사용해서 분석 결과를 그림 형태로 나타내어 비즈니스 사용자들의 해석을 용이하게 한다. 그림에서 점선에 표시된 것과 같이 피드백을 제공할 수 있어야 한다.

같은 결과라도 여러가지 방법으로 나타내어질 수 있고, 이는 결과의 해석에도 영향을 미칠 수 있다. 비즈니스 도멘이에서 가장 적합한 시각화 방법을 사용하는 것이 중요하다. 

#### 분석 결과 활용

분석된 데이터의 적합한 활용 장소와 방법을 결정한다. 분석 대상이 되는 문제의 특징에 따라, 분석 결과가 분석된 데이터에 내재되어 있는 패턴과 관계에 대한 새로운 인사이트를 제공하는 `모델`을 생성할 수 있다. 그 모델은 수식의 형태이거나 일련의 규칙들로 이뤄졌을 수도 있다. 

+ 기업 시스템에 입력 : 기업의 운영 최적화 및 실적 향상에 이용된다. 

> 예를들어, 고객 관련 분석 결과를 온라인 상점에 적용하여 제품을 추천하는 방법에 영향을 줄 수 있다. 새로운 모델은 기존 기업 시스템의 프로그래밍 로직을 향상시키는 데 사용되거나 새로운 시스템의 기초를 형성한다.

+ 비즈니스 프로세스 최적화 : 패턴, 상관관계, 이상치는 비즈니스 프로세스를 개선하는 데 사용된다. 

> 예를들어, 공급망 프로세스의 일부로 운송 루트를 통합하는 경우가 있다. 

+ 경고 : 기존 경고 시스템에 입력되거나, 새로운 경고 시스템의 기초를 형성할 수 있다. 

> 예를들어, 조치를 취해야 하는 사건이 발생할 경우, 사용자에게 알려준다. (신용카드 해외 사기 사용시 등)